{
    "n_positions": 1024,
    "n_embed": 1536,
    "n_layers": 16,
    "n_heads": 6,
    "n_ff": 6144,
    "n_vocab": 32760,
    "act_fn": "DecoderLayer(\n  (mh_attn): MultiHeadAttention(\n    (layer_1): Linear(in_features=1536, out_features=4608, bias=True)\n    (W_o): Linear(in_features=1536, out_features=1536, bias=True)\n  )\n  (mha_dropout): Dropout(p=0.2, inplace=False)\n  (mha_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n  (ff_layers): Sequential(\n    (0): Linear(in_features=1536, out_features=6144, bias=True)\n    (1): GELU(approximate='none')\n    (2): Linear(in_features=6144, out_features=1536, bias=True)\n  )\n  (ff_dropout): Dropout(p=0.2, inplace=False)\n  (ff_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n)",
    "dropout": "unknown",
    "stats": {
        "iter_through": 1150,
        "tok_through": 4710400,
        "losses": [
            11.4375,
            11.4375,
            10.6875,
            10.75,
            10.75,
            10.1875,
            10.125,
            9.8125,
            9.875,
            10.0625,
            10.1875,
            10.1875,
            9.75,
            9.6875,
            9.6875,
            9.5,
            9.4375,
            9.25,
            9.25,
            9.375,
            9.125,
            9.1875,
            9.3125
        ],
        "tok_snap": 143360,
        "time_snap": 1750670326.0941222,
        "run_time_start": 1750669778.2283764,
        "run_tok_through": 4710400,
        "run_iter_through": 1150
    }
}